# DataStreamAPI（1.7版）
## 执行流程
- 设置执行环境
- 读取输入流
- 应用转换
- 输出结果
- 执行

Flink程序都是通过延迟计算（lazily execute）的方式执行。也就是说，那些创建数据源和转换操作的API调用不会立即触发数据处理，而只会在执行环境中构建
一个执行计划。计划中包含了从环境创建的流式数据源以及应用于这些数据源之上的一系列转换。只有在调用execute()方法时，系统才会触发程序执行。

构建完的JobGraph并提交到JobManager执行。根据执行环境类型的不同，系统可能需要将JobGraph发送到作为本地线程启动的JobManager上，也可能会将其发送
到远程的JobManager上。如果是后者，除JobGraph之外，我们还需要同时提供包含应用所需全部类和依赖的JAR包。

## 转换操作
### 完成一个DataStream API程序在本质上可以归结为：通过组合不同的转换来创建一个满足应用逻辑的Dataflow图。

将DataStream API的转换分为四类：
- 作用于单个事件的基本转换
- 针对相同键值事件的KeyedStream转换
- 将多条数据流合并为一条或将一条数据流拆分成多条流的转换
- 对流中的事件进行重新组织的分发转换

### 基本转换
#### Map
通过调用DataStream.map()方法可以指定map转换产生一个新的DataStream。

MapFunction的两个类型参数分别是输入事件和输出事件的类型，它们可以通过MapFunction接口来指定。该接口的map()方法将每个输入事件转换为一个输出事件。

#### Filter
Filter转换利用一个作用在流中每条输入事件上的布尔条件来决定事件的去留，如果返回值为true，那么它会保留输入事件并将其转发到输出，否则它会把事件丢弃。
通过调用DataStream.filter()方法可以指定filter转换产生一个数据类型不变的DataStream。

#### FlatMap
flatMap转换类似于Map，但它可以对每个输入事件产生零个、一个或多个输出事件。

### 基于KeyedStream的转换
作为DataStream API中一类特殊的DataStream，KeyedStream抽象可以从逻辑上将事件按照键值分配到多条独立的子流中。

作用于KeyedStream的状态化转换可以对当前处理事件的键值所对应上下文中的状态进行读写。这意味着所有键值相同的事件可以访问相同的状态。

#### keyBy
keyBy转换通过指定键值的方式将一个DataStream转化为KeyedStream。流中的事件会根据各自键值被分到不同的分区，这样一来，有着相同键值的事件一定会在后
续算子的同一个任务上处理。虽然键值不同的事件也可能会在同一个任务上处理，但任务函数所能访问的键值分区状态始终会被约束在当前事件键值的范围内。

#### 滚动聚合
滚动聚合转换作用于KeyedStream上，它将生成一个包含聚合结果（例如 求和、最小值、最大值等）的DataStream。滚动聚合算子会对每一个遇到过的键值保存一
个聚合结果。每当有新事件到来，该算子都会更新相应的聚合结果，并将其以事件的形式发送出去。

DataStream API中提供了以下滚动聚合方法：
- sum()：滚动计算输入流中指定字段的和
- min()：滚动计算输入流中指定字段的最小值
- max()：滚动计算输入流中指定字段的最大值
- minBy()：滚动计算输入流中迄今为止最小值，返回该值所在事件
- maxBy()：滚动计算输入流中迄今为止最大值，返回该值所在事件

> Tips：无法将多个滚动聚合方法组合使用，每次只能计算一个

#### Reduce
reduce转换是滚动聚合转换的泛化。它将一个ReduceFunction应用在一个KeyedStream中，每个到来的事件都会和reduce结果进行一次组合，从而产生一个新的
DataStream。reduce转换不会改变数据类型，因此输出流的类型会永远和输入流保持一致。


