# 状态化流处理概述
## ApacheFlink架构
### Flink组件
Flink搭建需要四个不同组件，它们相互协作，共同执行流式应用，这些组件分别是：JobManager、ResourceManager、TaskManager、Dispatcher
#### JobManager
- 作为主进程（Master Process），JobManager控制着耽搁应用程序的执行。换句话说，每个应用都由一个不同的JobManager掌控。
- JobManager可以接收需要执行的应用，该应用包含一个所谓的JobGraph，即逻辑Dataflow图，以及一个打包了全部所需类、库以及其他资源的JAR文件，
- JobManager会把JobGraph转换为ExecutionGraph的物理Dataflow图，该图包含了哪些可以并行执行的任务。
- JobManager从ResourceManager申请执行任务的必要资源（TaskManager处理槽），一旦它收到了足够数量的TaskManager处理槽（slot），就会将
ExecutionGraph中的任务分发给TaskManager来执行。
- 在执行过程中，JobManager还要负责所有需要集中协调的操作，eg：创建检查点 等

#### ResourceManager
- 针对不同的环境和资源提供者（resource provider）（如 YARN、Mesos、Kubernetes或独立部署），Flink提供了不同的ResourceManager。
- ResourceManager负责管理Flink的处理资源单元—> TaskManager处理槽。
- 当JobManager申请TaskManager处理槽时，ResourceManager会指示一个拥有空闲处理槽的TaskManager将其处理槽提供给JobManager。
- 如果ResourceManager的处理槽数无法满足JobManager的请求，则ResourceManager可以和资源提供者通信，让它们提供额外容器来启动更多TaskManager
进程。同时ResourceManager还负责终止空闲的TaskManager以释放计算资源。

#### TaskManager
- TaskManager是Flink的工作进程（work process），通常在Flink搭建过程中要启动多个TaskManager。每个TaskManager提供一定数量的处理槽。处理
槽的数目限制了一个TaskManager可执行的任务数。
- TaskManager在启动后，会向ResourceManager注册它的处理槽。当接收到ResourceManager的指示时，TaskManager会向JobManger提供一个或多个处理
槽（slot）。之后JobManager就可以向处理槽中分配任务来执行。
- 在执行期间，运行同一应用不同任务的TaskManager之间会产生数据交换。

#### Dispatch
- Dispatch会跨多个作业运行，它提供了一个REST接口来让我们提交需要执行的应用。一旦某个应用提交执行，Dispatch会启动一个JobManager并将应用转交给它。
- REST接口意味着Dispatcher这一集群的HTTP入口可以受到防火墙的保护。
- Dispatch同时还会启动一个Web UI，用来提供有关作业执行的信息。
![](images/Flink各组件交互过程.png)
  
### 应用部署
Flink应用可以通过两种模式进行部署
#### 框架模式
- 在该模式下，Flink应用会打包成一个JAR文件，通过客户端提交到运行的服务上。(Flink Dispatcher、Flink JobManager、YARN的 Resource Manager)
- 如果应用提交到JobManager，则会立即执行；如果应用提交到Dispatcher或YARN ResourceManager，会启动一个JobManager并将应用转交给它，随后由
JobManager负责执行该应用。
  
#### 库模式
- 在该模式下，Flink应用会绑定到一个特定应用的容器镜像（如 Docker镜像）中。
- 镜像中还包含着运行JobManager以及ResourceManager的代码，当容器从镜像启动后会自动加载ResourceManager和JobManager，并将绑定的作业提交执行。
另一个和作业无关的镜像负责部署TaskManager容器。

### 任务执行
一个TaskManager允许同时执行多个任务。这些任务可以属于同一算子（数据并行），也可以是不同算子（任务并行），甚至还可以来自不同的应用（作业并行）。

TaskManager通过提供固定数量的处理槽来控制可以并行执行的任务数。每个处理槽可以执行应用的一部分，即算子的一个并行任务。

![](images/算子、任务、处理槽.png)

左侧的JobGraph（应用非并行化）包含了5个算子，其中算子A和C是数据源，算子E是数据汇。算子C和E的并行度是3，其余算子的并行度是4。
由于最大算子的并行度是4，因此应用若要执行则最少需要4个处理槽。

将任务以切片的形式调度至处理槽中有一个好处：
- TaskManager中的多个任务可以在同一进程内高效地执行数据交换而无须访问网络，然而，任务过于集中也会使TaskManager负载变高，继而可能导致性能下降。

### 高可用设置
#### TaskManager故障
假设一个Flink设置包含4个TaskManager，每个TaskManager有2个处理槽，那么一个流失应用最多支持以并行度8来运行，如果有一个TaskManager出现故障，则
可用的处理槽的数量就降到了6个，这时JobManager就会向ResourceManager申请更多的处理擦，若无法完成，JobManager就无法重启应用，直到有足够数量的可用
处理槽。

- 应用的重启策略决定了对JobManager以何种频率重启应用以及重启尝试之间的等待间隔。

#### JobManager故障
- 和TaskManager相比，JobManager用于控制流式应用执行以及保存该过程中的元数据（如已完成检查点的存储路径）。
- 如发生故障，导致JobManager成为Flink应用中的一个单点失效组件。为了解决该问题，Flink提供了高可用模式，支持在原JobManager消失的情况下，将作业
的管理职责及元数据迁移到另一个JobManager
  
Flink高可用模式是基于Apache Zookeeper来完成的。
- JobManager在高可用模式下工作时，会将JobGraph以及全部所需的元数据（例如 应用的JAR文件）写入一个远程持久化存储系统中。
- JobManager还会将存储位置的路径写入到Zookeeper的数据存储。
- 在应用执行过程中，JobManager会接收每个任务检查点的状态句柄（存储位置），在检查点即将完成的时候，如果所有任务已经将各自状态写入远程存储，JobManager
就会将状态句柄写入远程存储，并将远程位置的路径地址写入Zookeeper

![](images/Flink高可用设置.png)

当JobManager发生故障时，其下应用的所有任务都会自动取消。新接收工作的JobManager会执行以下步骤：
- 向Zookeeper请求存储位置，以获取JobGraph、JAR文件及应用最新检查点在远程存储的状态句柄
- 向ResourceManager申请处理槽来继续执行应用
- 重启应用利用最近一次检查点来重置任务状态

> Tips 如果是在容器环境（Kubernetes）中以库模式部署运行应用，容器编排服务（orchestration service）通常会自动重启故障的JobManager或TaskManager，

### Flink中的数据传输
在运行过程中，应用的任务会持续进行数据交换，TaskManager负责将数据从发送任务传输至接收任务。它的网络模块会在记录传输前会将它们收集到缓冲区中。换言之，
记录并非逐个发送的，而是在缓冲区中以批次形式发送。

- 每个TaskManager都有一个用于收发数据的网络缓冲池（默认32KB）
- 如果发送端和接收端的任务运行在不同的TaskManager进程中，它们就要用到操作系统的网络栈进行通信。
- 流式应用需要以流水线方式交换数据，因此每对TaskManager之间都要维护一个或多个永久的TCP连接来执行数据交换。
- 在Shuffle连接模式下，每个发送端任务都需要向任意一个接收任务传输数据，对于每一个接收任务，TaskManager都要提供一个专用的网络缓冲区，用于接收其他
  任务发来的数据
- 当发送任务和接收任务处于同一个TaskManager进程时，发送任务会将要发送的记录序列化到一个字节缓冲区中，一旦该缓冲区占满就会放到一个队列里。接收任务
会从这个队列里获取缓冲区并将其记录反序列化。
  
### 基于信用值（credit-based）的流量控制
Flink实现了一个基于信用值（credit-based）的流量控制机制，默认开启任务链接

它的工作原理如下：
- 接收任务会给发送任务授予一定的信用值，其实就是保留一些用来接收它数据的网络缓冲，一旦发送端收到信用通知，就会在信用值所限定的范围内尽可能多地传输
缓冲数据，并会附带上积压量（已经填满准备传输的网络缓冲数目）大小。接收端使用保留的缓冲来处理收到的数据，同时依据各发送端的积压量信息来计算所有相连
的发送端在下一轮的信用优先级
  
- 由于发送端可以在接收端有足够资源时立即传输数据，所以基于信用值的流控可以有效降低延迟。此外，信用值的授予是根据各发送端的数据积压量来完成的，因此该
机制还能在数据倾斜（data skew）时有效分配网络资源。
  
### 任务链接
Flink采用一种名为任务链接的优化技术来降低某些情况下的本地通信开销。

任务链接的前提是，多个算子必须有相同的并行度且通过本地转发通道（local forward channel）相连。

在任务链接模式下，多个算子的函数被"融合"到同一个任务中，在同一个线程内执行。函数生成的记录只需通过简单的方法调用就可以分别发往各自的下游函数，因此
基本函数之间的记录传输基本不会存在序列化及通信开销

### 事件时间处理
处理时间基于处理机器的本地时间，会产生一些较为随意，不一致且无法重现的结果，相反，事件时间会生成可重现且一致的结果

### 时间戳 
当Flink以事假时间模式来处理数据流时，会根据记录的时间戳触发时间相关算子的计算。

Flink内部采用8字节的Long值对时间戳进行编码，并将它们以元数据（metadata）的形式附加在记录上。内置算子会将这个Long值解析为毫秒精度的Unix时间戳。

### 水位线
Flink基于事件时间的应用还必须提供水位线（watermark），水位线用于在事件时间应用中推断每个任务当前的事件时间。基于时间的算子会使用这个时间来触发计
算并推动进度前进。

在Flink中，水位线是利用一些包含Long值时间戳的特殊记录来实现的。

![img.png](images/watermark.png)
水位线拥有两个基本属性：
- 必须单调递增。这是为了确保任务中的事件时间时钟正确前进，不会倒退。
- 和记录时间的时间戳存在联系，一个时间戳为T的水位线表示，接下来所有记录的时间戳一定都大于T

### 水位线传播和事件时间
Flink内部将水位线实现为特殊的记录，它们可以通过算子任务进行接收和发送。任务内部的时间服务（time service）会维护一些计时器（timer），它们依靠水位
线来激活。这些计时器是由任务在时间服务内注册，并在将来的某个时间点执行计算。

当任务接收到一个水位线时会执行以下操作：
- 基于水位线记录的时间戳更新内部事件时间时钟
- 任务的时间服务会找出所有触发时间小于更新后事件时间的计时器。对于每个到期的计时器，调用回调函数，利用它来执行计算或发出记录
- 任务根据更新后的事件时间将水位线发出

任务在接收到一个新的水位线之后，将如何发送水位线和更新其内部事件时间时钟？
- Flink会将数据流划分为不同的分区，并将它们交由不同的算子任务来并行执行，每个分区作为一个数据流，都会包含带有时间戳的记录以及水位线。根据算子的上
下游连接情况，其任务可能需要同时接收来自多个输入分区的记录和水位线，也可能需要将它们发送到多个输出分区。
  
一个任务会为它的每一个输入分区都维护一个分区水位线（partition watermark），当收到某个分区传来的水位线后，任务会以接收值和当前值取较大的那个值去
更新对应分区水位线的值。随后，任务会把事件时间时钟调整为所有分区水位线中最小的那个值。如果事件时间时钟向前推动，任务会先处理因此而触发的所有计时器，
之后才会把对应的水位线发往所有连接的输出分区，以实现事件时间到全部下游任务的广播。

![img.png](images/利用水位线更新任务的事件时间.png)







