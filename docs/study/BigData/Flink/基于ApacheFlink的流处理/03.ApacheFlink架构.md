# 状态化流处理概述
## ApacheFlink架构
### Flink组件
Flink搭建需要四个不同组件，它们相互协作，共同执行流式应用，这些组件分别是：JobManager、ResourceManager、TaskManager、Dispatcher
#### JobManager
- 作为主进程（Master Process），JobManager控制着耽搁应用程序的执行。换句话说，每个应用都由一个不同的JobManager掌控。
- JobManager可以接收需要执行的应用，该应用包含一个所谓的JobGraph，即逻辑Dataflow图，以及一个打包了全部所需类、库以及其他资源的JAR文件，
- JobManager会把JobGraph转换为ExecutionGraph的物理Dataflow图，该图包含了哪些可以并行执行的任务。
- JobManager从ResourceManager申请执行任务的必要资源（TaskManager处理槽），一旦它收到了足够数量的TaskManager处理槽（slot），就会将
ExecutionGraph中的任务分发给TaskManager来执行。
- 在执行过程中，JobManager还要负责所有需要集中协调的操作，eg：创建检查点 等

#### ResourceManager
- 针对不同的环境和资源提供者（resource provider）（如 YARN、Mesos、Kubernetes或独立部署），Flink提供了不同的ResourceManager。
- ResourceManager负责管理Flink的处理资源单元—> TaskManager处理槽。
- 当JobManager申请TaskManager处理槽时，ResourceManager会指示一个拥有空闲处理槽的TaskManager将其处理槽提供给JobManager。
- 如果ResourceManager的处理槽数无法满足JobManager的请求，则ResourceManager可以和资源提供者通信，让它们提供额外容器来启动更多TaskManager
进程。同时ResourceManager还负责终止空闲的TaskManager以释放计算资源。

#### TaskManager
- TaskManager是Flink的工作进程（work process），通常在Flink搭建过程中要启动多个TaskManager。每个TaskManager提供一定数量的处理槽。处理
槽的数目限制了一个TaskManager可执行的任务数。
- TaskManager在启动后，会向ResourceManager注册它的处理槽。当接收到ResourceManager的指示时，TaskManager会向JobManger提供一个或多个处理
槽（slot）。之后JobManager就可以向处理槽中分配任务来执行。
- 在执行期间，运行同一应用不同任务的TaskManager之间会产生数据交换。

#### Dispatch
- Dispatch会跨多个作业运行，它提供了一个REST接口来让我们提交需要执行的应用。一旦某个应用提交执行，Dispatch会启动一个JobManager并将应用转交给它。
- REST接口意味着Dispatcher这一集群的HTTP入口可以受到防火墙的保护。
- Dispatch同时还会启动一个Web UI，用来提供有关作业执行的信息。
![](images/Flink各组件交互过程.png)
  
### 应用部署
Flink应用可以通过两种模式进行部署
#### 框架模式
- 在该模式下，Flink应用会打包成一个JAR文件，通过客户端提交到运行的服务上。(Flink Dispatcher、Flink JobManager、YARN的 Resource Manager)
- 如果应用提交到JobManager，则会立即执行；如果应用提交到Dispatcher或YARN ResourceManager，会启动一个JobManager并将应用转交给它，随后由
JobManager负责执行该应用。
  
#### 库模式
- 在该模式下，Flink应用会绑定到一个特定应用的容器镜像（如 Docker镜像）中。
- 镜像中还包含着运行JobManager以及ResourceManager的代码，当容器从镜像启动后会自动加载ResourceManager和JobManager，并将绑定的作业提交执行。
另一个和作业无关的镜像负责部署TaskManager容器。

### 任务执行
一个TaskManager允许同时执行多个任务。这些任务可以属于同一算子（数据并行），也可以是不同算子（任务并行），甚至还可以来自不同的应用（作业并行）。

TaskManager通过提供固定数量的处理槽来控制可以并行执行的任务数。每个处理槽可以执行应用的一部分，即算子的一个并行任务。

![](images/算子、任务、处理槽.png)

左侧的JobGraph（应用非并行化）包含了5个算子，其中算子A和C是数据源，算子E是数据汇。算子C和E的并行度是3，其余算子的并行度是4。
由于最大算子的并行度是4，因此应用若要执行则最少需要4个处理槽。

将任务以切片的形式调度至处理槽中有一个好处：
- TaskManager中的多个任务可以在同一进程内高效地执行数据交换而无须访问网络，然而，任务过于集中也会使TaskManager负载变高，继而可能导致性能下降。

### 高可用设置
#### TaskManager故障
假设一个Flink设置包含4个TaskManager，每个TaskManager有2个处理槽，那么一个流失应用最多支持以并行度8来运行，如果有一个TaskManager出现故障，则
可用的处理槽的数量就降到了6个，这时JobManager就会向ResourceManager申请更多的处理擦，若无法完成，JobManager就无法重启应用，直到有足够数量的可用
处理槽。

- 应用的重启策略决定了对JobManager以何种频率重启应用以及重启尝试之间的等待间隔。

#### JobManager故障
- 和TaskManager相比，JobManager用于控制流式应用执行以及保存该过程中的元数据（如已完成检查点的存储路径）。
- 如发生故障，导致JobManager称为Flink应用中的一个单点失效组件。为了解决该问题，Flink提供了高可用模式，支持在原JobManager消失的情况下，将作业
的管理职责及元数据迁移到另一个JobManager
  
Flink高可用模式是基于Apache Zookeeper来完成的。
- JobManager在高可用模式下工作时，会将JobGraph以及全部所需的元数据（例如 应用的JAR文件）写入一个远程持久化存储系统中。
- JobManager还会将存储位置的路径写入到Zookeeper的数据存储。
- 在应用执行过程中，JobManager会接收每个任务检查点的状态句柄（存储位置），在检查点即将完成的时候，如果所有任务已经将各自状态写入远程存储，JobManager
就会将状态句柄写入远程存储，并将远程位置的路径地址写入Zookeeper

![](images/Flink高可用设置.png)













