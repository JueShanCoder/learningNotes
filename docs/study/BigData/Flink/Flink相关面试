# Flink 中的核心概念和基础考察
Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。并且 Flink 提供了数据分布、容错机制以及资源管理等核心功能。
Flink提供了诸多高抽象层的API以便用户编写分布式任务：

DataSet API， 对静态数据进行批处理操作，将静态数据抽象成分布式的数据集，用户可以方便地使用Flink提供的各种操作符对分布式数据集进行处理，支持Java、Scala和Python。
DataStream API，对数据流进行流处理操作，将流式的数据抽象成分布式的数据流，用户可以方便地对分布式数据流进行各种操作，支持Java和Scala。
Table API，对结构化数据进行查询操作，将结构化数据抽象成关系表，并通过类SQL的DSL对关系表进行各种查询操作，支持Java和Scala。



此外，Flink 还针对特定的应用领域提供了领域库，例如：Flink ML，Flink 的机器学习库，提供了机器学习Pipelines API并实现了多种机器学习算法。Gelly，Flink 的图计算库，提供了图计算的相关API及多种图计算算法实现。

# Flink 相比传统的 Spark Streaming 有什么区别?
Flink 是标准的实时处理引擎，基于事件驱动。而 Spark Streaming 是微批（Micro-Batch）的模型。
架构模型：
    - SparkStreaming在运行时的主要角色包括： Master、Worker、Driver、Executor
    - Flink： JobManager、Taskmanager、Slot
任务调度：
    - Spark Streaming 连续不断的生成微小的数据批次，构建有向无环图DAG，Spark Streaming 会依次创建 DStreamGraph、JobGenerator、JobScheduler。
    - Flink 根据用户提交的代码生成 StreamGraph，经过优化生成 JobGraph，然后提交给 JobManager进行处理，JobManager 会根据 JobGraph 生成 ExecutionGraph，ExecutionGraph 是 Flink 调度最核心的数据结构，JobManager 根据 ExecutionGraph 对 Job 进行调度。
时间机制：
    - Spark Streaming 支持的时间机制有限，只支持处理时间。Flink 支持了流处理程序在时间上的三个定义：处理时间、事件时间、注入时间。同时也支持 watermark 机制来处理滞后数据。
容错机制：
    - 对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰一次处理语义。
    
# 阐述Flink如何处理反压，相比Storm、Spark Streaming提供的反压机制，描述其实现有什么不同？

# 阐述流处理引擎提供的三种数据处理语义，解释Flink Checkpoint机制如何保证Flink程序结果的Exactly-Once语义，描述如何通过两阶段提交协议提供端到端的Exactly-Once保证？结合Kafka如何构建端到端的Exactly-Once处理？

# 阐述Flink提供的容错机制，解释分布式快照Chandy Lamport算法逻辑，剖析Flink Checkpoint具体实现流程？

# 如何处理Flink作业频繁重启问题？

# 如何优化大状态的Flink作业？

# 如何排查Flink Checkpoint超时问题？

# 如何处理Flink作业中的数据倾斜问题？

# Flink反压机制，如何排查反压瓶颈在哪及如何处理反压问题？

# 哪种join可以满足耽搁流断流的时候仍然能保证正确的join到数据？

# watermark是怎么生成和传递的？


